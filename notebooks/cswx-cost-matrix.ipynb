{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from search_strategies import create_search_strategy\n",
    "from pcfg import PCFG\n",
    "from grammars import grammars\n",
    "from evaluation import evaluation_fn\n",
    "from arguments import parse_arguments\n",
    "from data import get_data_loaders\n",
    "from utils import load_config, Limiter\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "\n",
    "from search_state import DerivationTreeNode, Operation\n",
    "from grammars import einspace\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import skewnorm\n",
    "\n",
    "from visualise import visualise_derivation_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c 'import sys; print(sys.executable)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS():\n",
    "    def __init__(self, config, device):\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        self.acquisition_fn = \"uct\"\n",
    "        self.exploration_weight=1.0\n",
    "        self.incubent_type=\"parent\"\n",
    "        self.reward_mode=\"sum\"\n",
    "        self.regularised=True\n",
    "        self.vis_interval = 10\n",
    "        \n",
    "args = ARGS(\"D:/Adri/Projects/NAS/einspace/einsearch-main_new/configs/einspace_quick/evolution_test/addnist/evolution.yaml\", \"cpu\")\n",
    "args = load_config(args)\n",
    "args.individual_memory = args.mem_limit\n",
    "args.dataset = \"addnist\"\n",
    "args.generational = False\n",
    "args.regularised = True\n",
    "args.elitism = 0\n",
    "args.mutation_rate = 0.0\n",
    "args.crossover_strategy = None\n",
    "args.crossover_rate = 0\n",
    "args.load_in_gpu = False\n",
    "args.channels = 3\n",
    "args.load_from = \"a\"\n",
    "args.architecture_seed = 0\n",
    "args.add_full_paths = True\n",
    "args.n_tries = 10\n",
    "#args.time_limit = 10\n",
    "#pprint(vars(args))\n",
    "\n",
    "# set the seed\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "# create the limiter\n",
    "# this makes sure that the search does not exceed\n",
    "# time, memory (GPU and RAM), depth, or node limits during the search\n",
    "limiter = Limiter(\n",
    "    limits={\n",
    "        \"time\": args.time_limit,\n",
    "        \"max_id\": args.max_id_limit,\n",
    "        \"depth\": args.depth_limit,\n",
    "        \"memory\": args.mem_limit,\n",
    "        \"individual_memory\": args.individual_memory\n",
    "    }\n",
    ")\n",
    "\n",
    "# create the grammar\n",
    "grammar = PCFG(\n",
    "    grammar=grammars[args.search_space],\n",
    "    limiter=limiter,\n",
    ")\n",
    "#print(grammar)\n",
    "\n",
    "train_loader, val_loader, _, _ = get_data_loaders(\n",
    "    dataset=args.dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    image_size=args.image_size,\n",
    "    root=r\"D:\\Adri\\Projects\\NAS\\einspace\\einsearch-main_new\\data\",\n",
    "    load_in_gpu=args.load_in_gpu,\n",
    "    device=args.device,\n",
    "    log=args.verbose_eval,\n",
    ")\n",
    "\n",
    "eval_fn = partial(\n",
    "    evaluation_fn,\n",
    "    args=args,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    ")\n",
    "\n",
    "# create the input parameters\n",
    "input_params = {\n",
    "    \"shape\": torch.Size([1, args.channels, *args.image_size]),\n",
    "    \"other_shape\": None,\n",
    "    \"mode\": \"im\",\n",
    "    \"other_mode\": None,\n",
    "    \"branching_factor\": 1,\n",
    "    \"last_im_shape\": None,\n",
    "}\n",
    "\n",
    "# create the search strategy\n",
    "search = create_search_strategy(args, grammar, eval_fn, limiter, input_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixCell():\n",
    "    def __init__(self):\n",
    "        self.top = np.nan\n",
    "        self.left = np.nan\n",
    "        self.corner = np.nan\n",
    "        self.operation = (\"\", \"\", \"\")\n",
    "        self.value = np.nan\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.value)+\" \"+str(self.operation)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "class MatrixOperation(object):\n",
    "    def __init__(self, op_id = None, op_type = None, node1_id = None, node2_id = None, i = None, j = None, ii = None, jj = None, value = 0, disabler_ops = [], enabler_ops = []):\n",
    "        self.id = op_id\n",
    "        self.op_type = op_type\n",
    "        self.node1_id = node1_id\n",
    "        self.node2_id = node2_id\n",
    "        self.i = i\n",
    "        self.j = j\n",
    "        self.ii = ii\n",
    "        self.jj = jj\n",
    "        self.value = value\n",
    "        self.disabler_ops = disabler_ops\n",
    "        self.enabler_ops = enabler_ops\n",
    "        \n",
    "    def __str__(self):\n",
    "        string = self.op_type+\" (id: \"+str(self.id)+\") with a cost of \"+str(self.value)+\". \"\n",
    "        if len(self.disabler_ops):\n",
    "            string = string[:-2]+\" (disabled by \"\n",
    "            for branch in self.disabler_ops:\n",
    "                if type(branch) != list: branch = [branch]\n",
    "                for op in branch: string += str(op.id)+\", \"\n",
    "            if string[-3:] == \"by \": string += \"none, \"\n",
    "            string = string[:-2]+\").\"\n",
    "        if len(self.enabler_ops):\n",
    "            string = string[:-2]+\" (\"*(len(self.disabler_ops)==0)+\"; \"*(len(self.disabler_ops)>0)+\"enabled by \"\n",
    "            for branch in self.enabler_ops:\n",
    "                if type(branch) != list: branch = [branch]\n",
    "                for op in branch: string += str(op.id)+\", \"\n",
    "            if string[-3:] == \"by \": string += \"none, \"\n",
    "            string = string[:-2]+\").\"\n",
    "        return string\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.id == other.id\n",
    "    \n",
    "class DecoyOperation(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "class Decoy(object):\n",
    "    # This is an empty object to hold an operation name and id as if it was a node, as well as its parent and branch number if it is an end of branch decoy node\n",
    "    def __init__(self, parent, branch, name):\n",
    "        self.parent = parent\n",
    "        self.branch = branch\n",
    "        self.operation = DecoyOperation(name)\n",
    "        self.children = []\n",
    "        if parent is not None: self.id = self.parent.id\n",
    "        else: self.id = -1\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.id == other.id\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not self.__eq__(other)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.operation.name)+\" (id \"+str(self.id)+\")\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "class AlignmentMatrix():\n",
    "    def __init__(self, model1, model2, priorities = (\"mut\", \"add\", \"rem\"), verbose = False):\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.model1 = model1\n",
    "        if self.verbose: print(\"First model: \", self.model1)\n",
    "        self.model_ops1 = [Decoy(None, None, \"start_node\")] + self.breakdown(self.model1)\n",
    "        \n",
    "        self.model2 = model2\n",
    "        self.new_node_id = max([node.id for node in self.model1.serialise()])+1\n",
    "        for node in self.model2.serialise(): self.update_id(node) # We reset the models' node ids to avoid anything breaking when we combine the models because of id repetitions\n",
    "        if self.verbose: print(\"Second model:\", self.model2)\n",
    "        self.model_ops2 = [Decoy(None, None, \"start_node\")] + self.breakdown(self.model2)\n",
    "        \n",
    "        self.size = (len(self.model_ops1), len(self.model_ops2))\n",
    "        self.operations = []\n",
    "        self.nontrivial_ops = []\n",
    "        \n",
    "        timestart = time.time()\n",
    "        self.matrix = self.calculate_matrix(self.model_ops1, self.model_ops2, corner_value = 0, corner_op = \"start\", block_idx=(0,0), priorities = priorities)\n",
    "        self.trace_back()\n",
    "        if self.verbose:\n",
    "            print(\"\\nDistance of\", round(self.distance,2), \"through\", len(self.nontrivial_ops), \"operations, calculated in\" ,round((time.time()-timestart)*1000,2),\"ms.\"), self.print_alignment_matrix()\n",
    "    \n",
    "    def breakdown(self, model):\n",
    "        model_ops = []\n",
    "        \n",
    "        condition = model.operation\n",
    "        if model.parent: condition = condition and (\"computation\" not in model.parent.operation.name) \n",
    "            \n",
    "        if condition:\n",
    "            if not (\"sequential\" in model.operation.name):\n",
    "                model_ops = [model]\n",
    "                \n",
    "            if len(model.children) > 2: # If we have several children (branchings, routings...)\n",
    "                for child in range(1, len(model.children)-1): # And then add all the children's operations to the list\n",
    "                    model_ops += self.breakdown(model.children[child])\n",
    "                    model_ops += [Decoy(model, child, \"wrap_\"+\"end\"*(child==len(model.children)-2)+\"sep\"*(child!=len(model.children)-2))]\n",
    "                \n",
    "            else:\n",
    "                for child in model.children:\n",
    "                    model_ops += self.breakdown(child)\n",
    "    \n",
    "        return model_ops\n",
    "                \n",
    "    def print_alignment_matrix(self):\n",
    "        matrix = self.matrix\n",
    "        model_ops1 = self.model_ops1\n",
    "        model_ops2 = self.model_ops2\n",
    "            \n",
    "        length = 5\n",
    "        interval_space = 3\n",
    "        size = (len(matrix), len(matrix[0]))\n",
    "        m = np.zeros(size)\n",
    "        \n",
    "        plt.imshow(m)\n",
    "        ax = plt.gca()\n",
    "        ax.tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "        ax.set_yticks([x for x in range(len(model_ops1))])\n",
    "        ax.set_yticklabels([self.get_op_name(op).replace(\"wrap\", self.get_op_name(op.parent)) if \"wrap\" in self.get_op_name(op) else self.get_op_name(op) for op in model_ops1], rotation=0)\n",
    "        ax.set_xticks([y for y in range(len(model_ops2))])\n",
    "        ax.set_xticklabels([self.get_op_name(op).replace(\"wrap\", self.get_op_name(op.parent)) if \"wrap\" in self.get_op_name(op) else self.get_op_name(op) for op in model_ops2], rotation=90)\n",
    "        for i in range(size[0]):\n",
    "            for j in range(size[1]):\n",
    "                if \"add\" in matrix[i][j].operation:\n",
    "                    if \"wrap\" in model_ops1[i].operation.name: ax.plot((j, j), (i-1, i), linestyle = \"--\", dashes=(length, interval_space), color = \"dimgrey\")\n",
    "                    else: ax.plot((j, j), (i-1, i), color = \"dimgrey\")\n",
    "                if \"rem\" in matrix[i][j].operation:\n",
    "                    if \"wrap\" in model_ops2[j].operation.name: ax.plot((j-1, j), (i, i), linestyle = \"--\", dashes=(length, interval_space), color = \"dimgrey\")\n",
    "                    else: ax.plot((j-1, j), (i, i), color = \"dimgrey\")\n",
    "                if \"mut\" in matrix[i][j].operation: ax.plot((j-1, j), (i-1, i), color = \"dimgrey\")\n",
    "                m[i,j] = matrix[i][j].value\n",
    "\n",
    "        max_weight = 0\n",
    "        for op in self.nontrivial_ops:\n",
    "            max_weight = max(max_weight, op.value)\n",
    "        max_weight /= 0.66\n",
    "        max_weight += 0.00000001\n",
    "        \n",
    "        plt.imshow(m)\n",
    "        ax = plt.gca()\n",
    "        ax.tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "        ax.set_yticks([x for x in range(len(model_ops1))])\n",
    "        ax.set_yticklabels([self.get_op_name(op).replace(\"wrap\", self.get_op_name(op.parent)) if \"wrap\" in self.get_op_name(op) else self.get_op_name(op) for op in model_ops1], rotation=0)\n",
    "        ax.set_xticks([y for y in range(len(model_ops2))])\n",
    "        ax.set_xticklabels([self.get_op_name(op).replace(\"wrap\", self.get_op_name(op.parent)) if \"wrap\" in self.get_op_name(op) else self.get_op_name(op) for op in model_ops2], rotation=90)\n",
    "                    \n",
    "        length = 1.7\n",
    "        interval_space = 0.7\n",
    "        for op in self.operations:\n",
    "            weight_color = (0.33+(op.value/max_weight),0.33+((op.value)/max_weight),0.33+(op.value/max_weight))\n",
    "            if \"add_wrap_end\" in op.op_type: plt.plot((op.j, op.j), (op.i-1, op.i), linestyle = \"--\", dashes=(length, interval_space) ,color = weight_color, linewidth=4)\n",
    "            elif \"add_wrap_sep\" in op.op_type: plt.plot((op.j, op.j), (op.i-1, op.i), linestyle = \"--\", dashes=(length, interval_space) ,color = weight_color, linewidth=4)\n",
    "            elif \"add_\" in op.op_type: plt.plot((op.j, op.j), (op.i-1, op.i), color = weight_color, linewidth=4)\n",
    "            if \"rem_wrap_end\" in op.op_type: plt.plot((op.j-1, op.j), (op.i, op.i), linestyle = \"--\", dashes=(length, interval_space), color = weight_color, linewidth=4)\n",
    "            elif \"rem_wrap_sep\" in op.op_type: plt.plot((op.j-1, op.j), (op.i, op.i), linestyle = \"--\", dashes=(length, interval_space), color = weight_color, linewidth=4)\n",
    "            elif \"rem\" in op.op_type: plt.plot((op.j-1, op.j), (op.i, op.i), color = weight_color, linewidth=4)\n",
    "            if \"mut\" in op.op_type: plt.plot((op.j-1, op.j), (op.i-1, op.i), color = weight_color, linewidth=4)\n",
    "\n",
    "        plt.savefig(\"example_crossover.svg\", format='svg')\n",
    "        plt.show()\n",
    "\n",
    "    def get_op_name(self, op):\n",
    "        #if (\"routing\" in op.operation.name or \"branching\" in op.operation.name) and op.operation.name != \"branching(2)\": return op.operation.name.split(\"(\")[0]\n",
    "        if \"computation\" in op.operation.name: return \"comp<\"+op.children[0].operation.name+\">\"\n",
    "        else: return op.operation.name\n",
    "        \n",
    "    def calculate_matrix(self, model_ops1, model_ops2, corner_value = 0, corner_op = \"start\", block_idx=(0,0), priorities = (\"mut\", \"add\", \"rem\")):\n",
    "        priorities = sorted(range(len(priorities)), key=priorities.__getitem__)\n",
    "        priorities = sorted(range(len(priorities)), key=priorities.__getitem__)\n",
    "        \n",
    "        matrix = []\n",
    "        size = (len(model_ops1), len(model_ops2))\n",
    "        for i in range(size[0]): # We initialize the whole matrix with empty cells\n",
    "            row = []\n",
    "            for j in range(size[1]):\n",
    "                row.append(MatrixCell())\n",
    "            matrix.append(row)\n",
    "\n",
    "        for i in range(size[0]):\n",
    "            matrix[i][0].left = np.inf \n",
    "            matrix[i][0].corner = np.inf\n",
    "        for j in range(size[1]):\n",
    "            matrix[0][j].top = np.inf \n",
    "            matrix[0][j].corner = np.inf \n",
    "        matrix[0][0].value = 0\n",
    "        matrix[0][0].operation = [\"start\"]\n",
    "\n",
    "        self.matrix = matrix\n",
    "        for i in range(size[0]):\n",
    "            for j in range(size[1]):\n",
    "                if not np.isinf(matrix[i][j].top):\n",
    "                    if model_ops1[i].operation.name in [\"wrap_end\", \"wrap_sep\"]: # If we are trying to close a new branch,\n",
    "                        ii = i-1\n",
    "                        jj = j\n",
    "                        level = 0 # we keep track of how many branches/routings we go into or exit through the current path with this \"level\" tracker\n",
    "                        while model_ops1[i].id != model_ops1[ii].id:\n",
    "                            if self.matrix[ii][jj].operation == [\"add\"]:\n",
    "                                ii -= 1\n",
    "                            elif self.matrix[ii][jj].operation == [\"rem\"]:\n",
    "                                level = level - max(0, (len(model_ops2[jj].children)-2)) + (\"wrap_\" in model_ops2[jj].operation.name)\n",
    "                                jj -=1\n",
    "                            elif self.matrix[ii][jj].operation == [\"mut\"]:\n",
    "                                level = level - max(0, (len(model_ops2[jj].children)-2)) + (\"wrap_\" in model_ops2[jj].operation.name)\n",
    "                                ii -= 1\n",
    "                                jj -=1\n",
    "                            if level == -1: break # If we exit the outer branch/rout, we break this loop\n",
    "                        if (level==0) and (matrix[ii][jj].operation == [\"add\"]): matrix[i][j].top = matrix[i-1][j].value # If the branch was added within this depth, we allow the ending of the branch\n",
    "                        else: matrix[i][j].top = np.inf\n",
    "                    else: matrix[i][j].top = matrix[i-1][j].value + 1 # If we are not trying to close a branch, we simply sum the cost of adding whatever we're adding\n",
    "                    \n",
    "                if not np.isinf(matrix[i][j].left):\n",
    "                    if model_ops2[j].operation.name in [\"wrap_end\", \"wrap_sep\"]: # If we are trying to close a branch we removed,\n",
    "                        ii = i\n",
    "                        jj = j-1\n",
    "                        level = 0 # we keep track of how many branches/routings we go into or exit through the current path with this \"level\" tracker\n",
    "                        while model_ops2[j].id != model_ops2[jj].id:\n",
    "                            if self.matrix[ii][jj].operation == [\"add\"]:\n",
    "                                level = level - max(0, (len(model_ops1[ii].children)-2)) + (\"wrap_\" in model_ops1[ii].operation.name)\n",
    "                                ii -= 1\n",
    "                            elif self.matrix[ii][jj].operation == [\"rem\"]:\n",
    "                                jj -=1\n",
    "                            elif self.matrix[ii][jj].operation == [\"mut\"]:\n",
    "                                level = level - max(0, (len(model_ops1[ii].children)-2)) + (\"wrap_\" in model_ops1[ii].operation.name)\n",
    "                                ii -= 1\n",
    "                                jj -=1\n",
    "                            if level == -1: break # If we exit the outer branch/rout, we break this loop\n",
    "                        if (level==0) and (matrix[ii][jj].operation == [\"rem\"]): matrix[i][j].left = matrix[i][j-1].value # If the branch was removed within this depth, we allow the ending of the branch\n",
    "                        else: matrix[i][j].left = np.inf\n",
    "                    else: matrix[i][j].left = matrix[i][j-1].value + 1 # If we are not trying to close a branch, we simply sum the cost of removing whatever we're removing\n",
    "                \n",
    "                if not np.isinf(matrix[i][j].corner):\n",
    "                    if (model_ops1[i].operation.name in [\"wrap_end\", \"wrap_sep\"]) and (model_ops2[j].operation.name == model_ops1[i].operation.name): # If we are trying to close a branch we mutated into another,\n",
    "                        ii = i-1\n",
    "                        jj = j-1\n",
    "                        condition1 = model_ops1[i].id != model_ops1[ii].id\n",
    "                        condition2 = model_ops2[j].id != model_ops2[jj].id\n",
    "                        while condition1 or condition2: # we simply have to look at where we added/removed/mutated both branches\n",
    "                            if self.matrix[ii][jj].operation == [\"add\"]:\n",
    "                                ii -= 1\n",
    "                            elif self.matrix[ii][jj].operation == [\"rem\"]:\n",
    "                                jj -= 1\n",
    "                            elif self.matrix[ii][jj].operation == [\"mut\"]:\n",
    "                                ii -= 1\n",
    "                                jj -= 1\n",
    "                            condition1 = condition1 and (model_ops1[i].id != model_ops1[ii].id)\n",
    "                            condition2 = condition2 and (model_ops2[j].id != model_ops2[jj].id)\n",
    "                        if ((model_ops1[i].id == model_ops1[ii].id) and (model_ops2[j].id == model_ops2[jj].id)) and (matrix[ii][jj].operation == [\"mut\"]): matrix[i][j].corner = matrix[i-1][j-1].value # and if the branches were mutated, we allow the ending of the branch through mutation\n",
    "                        else: matrix[i][j].corner = np.inf\n",
    "                    else: matrix[i][j].corner = matrix[i-1][j-1].value + self.cost_mut(model_ops1[i], model_ops2[j]) # If we are not trying to close a branch, we simply sum the cost of mutating whatever we're mutating\n",
    "                    \n",
    "                if np.isnan(matrix[i][j].value):\n",
    "                    values = (matrix[i][j].top, matrix[i][j].corner, matrix[i][j].left)\n",
    "                    min_value = np.nanmin(values) # We check which would be the cheapest path\n",
    "                    matrix[i][j].value = min_value\n",
    "                    matrix[i][j].operation = [matrix[i][j].operation[idx]+(\"add\", \"mut\", \"rem\")[idx] for idx in priorities if values[idx] == min_value] # And we save the selected operation\n",
    "                    matrix[i][j].operation = [matrix[i][j].operation[0]] # For now we only take 1 operation, prioritizing mutation\n",
    "        \n",
    "        return matrix\n",
    "\n",
    "    def cost_mut(self, op1, op2, max_cost = np.inf):\n",
    "        if \"wrap_\" in op1.operation.name or \"wrap_\" in op2.operation.name:\n",
    "            return max_cost\n",
    "        elif op1.operation.name.split(\"(\")[0] == op2.operation.name.split(\"(\")[0]:\n",
    "            if max_cost == 1: # This only happens when comparing submodules\n",
    "                if op1.operation == op2.operation: return 0.\n",
    "                else: return 0.5\n",
    "            elif sum([op.operation.name == \"branching(2)\" for op in (op1,op2)]) == 1: return max_cost # We can't change a branching(2) into a branching(8) for instance\n",
    "            else: return (self.cost_mut(op1.children[0], op2.children[0], 1))/2 # If we substitute a computation/branching/rounting/whatever module by another, we compare the subtype of module\n",
    "                \n",
    "        else:\n",
    "            return max_cost\n",
    "            \n",
    "    def update_id(self, node):\n",
    "        node.id = self.new_node_id\n",
    "        self.new_node_id += 1\n",
    "\n",
    "    def split_sequentials(self, original_node, split_id):\n",
    "        if split_id not in [n.id for n in original_node.serialise()]: raise Exception(\"Provided id is not within provided sequential node\")\n",
    "        parent_node = original_node.parent\n",
    "        if not original_node.is_root(): child_idx = parent_node.children.index(original_node)\n",
    "        nodes_list = original_node.children\n",
    "\n",
    "        sequential_in_list = True\n",
    "        while sequential_in_list:\n",
    "            sequential_in_list = False\n",
    "            for n, node in enumerate(nodes_list):\n",
    "                if node.operation.name == \"sequential\":\n",
    "                    sequential_in_list = True\n",
    "                    nodes_list = nodes_list[:n] + node.children + nodes_list[n+1:]\n",
    "                    break\n",
    "\n",
    "        for n, node in enumerate(nodes_list):\n",
    "            if node.id == split_id: break\n",
    "        \n",
    "        list1 = nodes_list[:n]\n",
    "        list2 = nodes_list[n:]\n",
    "        \n",
    "        for _ in range(len(list1)-1):\n",
    "            child2 = list1.pop()\n",
    "            child1 = list1.pop()\n",
    "    \n",
    "            list1 += [DerivationTreeNode(0,\n",
    "                                         level=node.level,\n",
    "                                         parent=node.parent,\n",
    "                                         input_params=node.input_params,\n",
    "                                         depth=node.depth,\n",
    "                                         limiter=node.limiter,\n",
    "                                         operation = Operation(name=\"sequential\",\n",
    "                                                               build=einspace.build_sequential_module,\n",
    "                                                               infer=einspace.infer_sequential_module,\n",
    "                                                               valid=einspace.valid_sequential_module,\n",
    "                                                               inherit = [einspace.inherit_first_child,einspace.inherit_other_child],\n",
    "                                                               give_back = [einspace.give_back_default,einspace.give_back_default],\n",
    "                                                               type=\"nonterminal\",\n",
    "                                                               child_levels=[\"module\",\"module\"])\n",
    "                                        )]\n",
    "            \n",
    "            self.update_id(list1[-1])\n",
    "            list1[-1].children=[child1, child2]\n",
    "            child1.parent = list1[-1]\n",
    "            child2.parent = list1[-1]\n",
    "        \n",
    "        for _ in range(len(list2)-1):\n",
    "            child2 = list2.pop()\n",
    "            child1 = list2.pop()\n",
    "    \n",
    "            list2 += [DerivationTreeNode(0,\n",
    "                                         level=node.level,\n",
    "                                         parent=node.parent,\n",
    "                                         input_params=node.input_params,\n",
    "                                         depth=node.depth,\n",
    "                                         limiter=node.limiter,\n",
    "                                         operation = Operation(name=\"sequential\",\n",
    "                                                               build=einspace.build_sequential_module,\n",
    "                                                               infer=einspace.infer_sequential_module,\n",
    "                                                               valid=einspace.valid_sequential_module,\n",
    "                                                               inherit = [einspace.inherit_first_child,einspace.inherit_other_child],\n",
    "                                                               give_back = [einspace.give_back_default,einspace.give_back_default],\n",
    "                                                               type=\"nonterminal\",\n",
    "                                                               child_levels=[\"module\",\"module\"])\n",
    "                                        )]\n",
    "            \n",
    "            self.update_id(list2[-1])\n",
    "            list2[-1].children=[child1, child2]\n",
    "            child1.parent = list2[-1]\n",
    "            child2.parent = list2[-1]\n",
    "\n",
    "        if len(list2):\n",
    "            resequentialized_node = DerivationTreeNode(0,\n",
    "                                                       level=node.level,\n",
    "                                                       parent=node.parent,\n",
    "                                                       input_params=node.input_params,\n",
    "                                                       depth=node.depth,\n",
    "                                                       limiter=node.limiter,\n",
    "                                                       operation = Operation(name=\"sequential\",\n",
    "                                                                             build=einspace.build_sequential_module,\n",
    "                                                                             infer=einspace.infer_sequential_module,\n",
    "                                                                             valid=einspace.valid_sequential_module,\n",
    "                                                                             inherit = [einspace.inherit_first_child,einspace.inherit_other_child],\n",
    "                                                                             give_back = [einspace.give_back_default,einspace.give_back_default],\n",
    "                                                                             type=\"nonterminal\",\n",
    "                                                                             child_levels=[\"module\",\"module\"])\n",
    "                                                      )\n",
    "            self.update_id(resequentialized_node)\n",
    "            resequentialized_node.children=[list1[0], list2[0]]\n",
    "            list1[0].parent = resequentialized_node\n",
    "            list2[0].parent = resequentialized_node\n",
    "        else:\n",
    "            raise Exception(\"Unable to resequentialize as requested\")\n",
    "\n",
    "        if not original_node.is_root(): parent_node.children[child_idx] = resequentialized_node\n",
    "        resequentialized_node.parent = parent_node\n",
    "        return resequentialized_node\n",
    "\n",
    "    def trace_back(self, from_pos = \"end\", prioritize = []):\n",
    "        if from_pos == \"end\": from_pos = (self.size[0]-1, self.size[1]-1)\n",
    "        if self.verbose: print(\"\\nOperations to change from model 1 to model 2:\")\n",
    "        self.operations = []\n",
    "        self.distance = self.matrix[-1][-1].value\n",
    "        i=from_pos[0]\n",
    "        j=from_pos[1]\n",
    "        while not (i == 0 and j == 0):\n",
    "            op = None\n",
    "            for priority_op in prioritize: # We check if the prioritized operations are available (in order of priority)\n",
    "                if priority_op in self.matrix[i][j].operation:\n",
    "                    op = priority_op\n",
    "                    break\n",
    "            if not op: # If there was no priority, we simply select a random one\n",
    "                op = random.choice(self.matrix[i][j].operation)\n",
    "            \n",
    "            if op == \"add\":\n",
    "                value = self.matrix[i][j].value-self.matrix[i-1][j].value\n",
    "                if self.model_ops1[i].operation.name == \"wrap_end\": self.operations += [MatrixOperation(op_id = len(self.operations),\n",
    "                                                                                          op_type = \"add_wrap_end\",\n",
    "                                                                                          node1_id = self.model_ops1[i].id,\n",
    "                                                                                          node2_id = self.model_ops2[j].id,\n",
    "                                                                                          i = i,\n",
    "                                                                                          j = j)]\n",
    "                elif self.model_ops1[i].operation.name == \"wrap_sep\": self.operations += [MatrixOperation(op_id = len(self.operations),\n",
    "                                                                                                  op_type = \"add_wrap_sep\",\n",
    "                                                                                                  node1_id = self.model_ops1[i].id,\n",
    "                                                                                                  node2_id = self.model_ops2[j].id,\n",
    "                                                                                                  i = i,\n",
    "                                                                                                  j = j)]\n",
    "                    \n",
    "                elif (len(self.model_ops1[i].children) == 4): # If we have are adding a branching(2) (that is, parallelizing some modules),\n",
    "                    for sep_idx, sep_operation in enumerate(self.operations): # we look for the corresponding branch separator\n",
    "                        if (sep_operation.op_type == \"add_wrap_sep\") and (sep_operation.node1_id == self.model_ops1[i].id): break\n",
    "                    for end_idx, end_operation in enumerate(self.operations): # and the corresponding branch end\n",
    "                        if (end_operation.op_type == \"add_wrap_end\") and (end_operation.node1_id == self.model_ops1[i].id): break\n",
    "\n",
    "                    disabler_ops = []\n",
    "                    enabler_ops = []\n",
    "                    adds = [[],[]]\n",
    "                    muts = [[],[]]\n",
    "                    rems = [[],[]]\n",
    "                    for inside_op in self.operations[sep_idx+1:]:\n",
    "                        if inside_op.op_type == \"add_module\": adds[0] = adds[0] + [inside_op]\n",
    "                        if inside_op.op_type == \"mut\": muts[0] = muts[0] + [inside_op]\n",
    "                        if inside_op.op_type == \"rem\": rems[0] = rems[0] + [inside_op]\n",
    "                    if not len(muts[0]):\n",
    "                        for rem_op in rems[0]:\n",
    "                            rem_op.enabler_ops = rem_op.enabler_ops + adds[0]\n",
    "                            rem_op.disabler_ops = rem_op.disabler_ops + [rem_op2 for rem_op2 in rems[0] if rem_op2 != rem_op]\n",
    "                        disabler_ops = disabler_ops + [rems[0]]\n",
    "                        enabler_ops = enabler_ops + [adds[0]*len(rems[0])]\n",
    "                    for inside_op in self.operations[end_idx+1:sep_idx]:\n",
    "                        if inside_op.op_type == \"add_module\": adds[1] = adds[1] + [inside_op]\n",
    "                        if inside_op.op_type == \"mut\": muts[1] = muts[1] + [inside_op]\n",
    "                        if inside_op.op_type == \"rem\": rems[1] = rems[1] + [inside_op]\n",
    "                    if not len(muts[1]):\n",
    "                        for rem_op in rems[1]:\n",
    "                            rem_op.enabler_ops = rem_op.enabler_ops + adds[1]\n",
    "                            rem_op.disabler_ops = rem_op.disabler_ops + [rem_op2 for rem_op2 in rems[1] if rem_op2 != rem_op]\n",
    "                        disabler_ops = disabler_ops + [rems[1]]\n",
    "                        enabler_ops = enabler_ops + [adds[1]*len(rems[1])]\n",
    "                    \n",
    "                    self.operations += [MatrixOperation(op_id = len(self.operations),\n",
    "                                                  op_type = \"add_branch2\",\n",
    "                                                  node1_id = self.model_ops1[i].id,\n",
    "                                                  node2_id = self.model_ops2[j].id,\n",
    "                                                  i = i,\n",
    "                                                  j = j,\n",
    "                                                  ii = (sep_operation.i,end_operation.i),\n",
    "                                                  jj = (sep_operation.j,end_operation.j),\n",
    "                                                  value = value,\n",
    "                                                  disabler_ops = disabler_ops,\n",
    "                                                  enabler_ops = enabler_ops)]\n",
    "                    \n",
    "                    if (len(adds[0]) and (not len(rems[0])) and (not len(muts[0]))) or (len(adds[1]) and (not len(rems[1])) and (not len(muts[1]))): # If we don't remove anything from any branch, and we have to add everything that's inside,\n",
    "                        self.operations[-1].disabler_ops = self.operations[-1].disabler_ops + [[self.operations[-1]],[self.operations[-1]]] # the operation becomes its own disabler for both branches,\n",
    "                        self.operations[-1].enabler_ops = self.operations[-1].enabler_ops + adds # only enabled by adding anything inside each branch first\n",
    "                    if value and self.verbose: print(f\"\\t(+{value}) Parallelize using {self.get_op_name(self.model_ops1[i])} (id: {self.model_ops1[i+1].id}) from indexes {(i,j)} to {(end_operation.i,end_operation.j)}\")\n",
    "                \n",
    "                elif (len(self.model_ops1[i].children) == 3): # If we have some of those \"group-M-cat\" or \"rout-M-rout\" situations,\n",
    "                    for end_idx, end_operation in enumerate(self.operations): # we look for the corresponding branch end\n",
    "                        if (end_operation.op_type == \"add_wrap_end\") and (end_operation.node1_id == self.model_ops1[i].id): break\n",
    "                    \n",
    "                    disabler_ops = []\n",
    "                    enabler_ops = []\n",
    "                    adds = []\n",
    "                    muts = []\n",
    "                    rems = []\n",
    "                    for inside_op in self.operations[end_idx+1:]:\n",
    "                        if inside_op.op_type == \"add_module\": adds += [inside_op]\n",
    "                        if inside_op.op_type == \"mut\": muts += [inside_op]\n",
    "                        if inside_op.op_type == \"rem\": rems += [inside_op]\n",
    "                    if not len(muts):\n",
    "                        for rem_op in rems:\n",
    "                            rem_op.enabler_ops = rem_op.enabler_ops + adds\n",
    "                            rem_op.disabler_ops = rem_op.disabler_ops + [rem_op2 for rem_op2 in rems if rem_op2 != rem_op]\n",
    "                        disabler_ops = disabler_ops + rems\n",
    "                        enabler_ops = enabler_ops + adds*len(rems)\n",
    "                    \n",
    "                    self.operations += [MatrixOperation(op_id = len(self.operations),\n",
    "                                                  op_type = \"add_wrap\",\n",
    "                                                  node1_id = self.model_ops1[i].id,\n",
    "                                                  node2_id = self.model_ops2[j].id,\n",
    "                                                  i = i,\n",
    "                                                  j = j,\n",
    "                                                  ii = end_operation.i,\n",
    "                                                  jj = end_operation.j,\n",
    "                                                  value = value,\n",
    "                                                  disabler_ops = disabler_ops,\n",
    "                                                  enabler_ops = enabler_ops)]\n",
    "\n",
    "                    if len(adds) and (not len(rems)) and (not len(muts)): # If we don't remove anything, and we have to add everything that's inside,\n",
    "                        self.operations[-1].disabler_ops = self.operations[-1].disabler_ops + [self.operations[-1]] # the operation becomes its own disabler,\n",
    "                        self.operations[-1].enabler_ops = self.operations[-1].enabler_ops + adds # only enabled by adding anything inside the wrapper first\n",
    "                    if value and self.verbose: print(f\"\\t(+{value}) Add wrapper {self.get_op_name(self.model_ops1[i])} (id: {self.model_ops1[i+1].id}) from indexes {(i,j)} to {(end_operation.i,end_operation.j)}\")\n",
    "                else:\n",
    "                    self.operations += [MatrixOperation(op_id = len(self.operations),\n",
    "                                                      op_type = \"add_module\",\n",
    "                                                      node1_id = self.model_ops1[i].id,\n",
    "                                                      node2_id = self.model_ops2[j].id,\n",
    "                                                      i = i,\n",
    "                                                      j = j,\n",
    "                                                      value = value)]\n",
    "                    if value and self.verbose: print(f\"\\t(+{value}) Add {self.get_op_name(self.model_ops1[i])} (id: {self.model_ops1[i].id}) at indexes {(i,j)}\")\n",
    "                i -= 1\n",
    "\n",
    "            elif op == \"rem\":\n",
    "                if self.model_ops2[j].operation.name == \"wrap_end\": self.operations += [MatrixOperation(op_id = len(self.operations),\n",
    "                                                                                          op_type = \"rem_wrap_end\",\n",
    "                                                                                          node1_id = self.model_ops1[i].id,\n",
    "                                                                                          node2_id = self.model_ops2[j].id,\n",
    "                                                                                          i = i,\n",
    "                                                                                          j = j)]\n",
    "                elif self.model_ops2[j].operation.name == \"wrap_sep\": self.operations += [MatrixOperation(op_id = len(self.operations),\n",
    "                                                                                                  op_type = \"rem_wrap_sep\",\n",
    "                                                                                                  node1_id = self.model_ops1[i].id,\n",
    "                                                                                                  node2_id = self.model_ops2[j].id,\n",
    "                                                                                                  i = i,\n",
    "                                                                                                  j = j)]\n",
    "                else:\n",
    "                    value = self.matrix[i][j].value-self.matrix[i][j-1].value\n",
    "                    self.operations += [MatrixOperation(op_id = len(self.operations),\n",
    "                                                  op_type = \"rem\",\n",
    "                                                  node2_id = self.model_ops2[j].id,\n",
    "                                                  i = i,\n",
    "                                                  j = j,\n",
    "                                                  value = value)]\n",
    "                    \n",
    "                    if (len(self.model_ops2[j].children) == 3): # If we have some of those \"group-M-cat\" or \"rout-M-rout\" situations,\n",
    "                        for end_idx, end_operation in enumerate(self.operations):\n",
    "                            if (end_operation.op_type == \"rem_wrap_end\") and (end_operation.node2_id == self.model_ops2[j].id): break # we look for the corresponding branch end,\n",
    "                        adds = []\n",
    "                        muts = []\n",
    "                        rems = []\n",
    "                        for inside_op in self.operations[end_idx+1:-1]: # check the operations we perform and,\n",
    "                            if inside_op.op_type == \"add_module\": adds += [inside_op]\n",
    "                            if inside_op.op_type == \"mut\": muts += [inside_op]\n",
    "                            if inside_op.op_type == \"rem\": rems += [inside_op]\n",
    "                        if not len(muts): # if we are not forced to have modules inside regardless of the operations we perform,\n",
    "                            for rem_op in rems:\n",
    "                                rem_op.disabler_ops = rem_op.disabler_ops + rems # we forbid removing all layers inside the wrap\n",
    "                                rem_op.enabler_ops = rem_op.enabler_ops + adds + [self.operations[-1]] # unless we add any layer, or remove the wrap itself\n",
    "                    \n",
    "                    elif (len(self.model_ops2[j].children) == 4): # If we have are removing a branching(2) (that is, serializing some modules),\n",
    "                        for sep_idx, sep_operation in enumerate(self.operations): # we look for the corresponding branch separator\n",
    "                            if (sep_operation.op_type == \"rem_wrap_sep\") and (sep_operation.node2_id == self.model_ops2[j].id): break\n",
    "                        for end_idx, end_operation in enumerate(self.operations): # and the corresponding branch end\n",
    "                            if (end_operation.op_type == \"rem_wrap_end\") and (end_operation.node2_id == self.model_ops2[j].id): break\n",
    "                        adds = [[],[]]\n",
    "                        muts = [[],[]]\n",
    "                        rems = [[],[]] # and, for each branch\n",
    "                        for inside_op in self.operations[sep_idx+1:-1]:\n",
    "                            if inside_op.op_type == \"add_module\": adds[0] += [inside_op]\n",
    "                            if inside_op.op_type == \"mut\": muts[0] += [inside_op]\n",
    "                            if inside_op.op_type == \"rem\": rems[0] += [inside_op]\n",
    "                        if not len(muts[0]): # if we are not forced to have modules inside the branch regardless of the operations we perform,\n",
    "                            for rem_op in rems[0]:\n",
    "                                rem_op.disabler_ops = rem_op.disabler_ops + rems[0] # we forbid removing all layers inside the branch\n",
    "                                rem_op.enabler_ops = rem_op.enabler_ops + adds[0] + [self.operations[-1]] # unless we add any layer, or remove the wrap itself\n",
    "                        for inside_op in self.operations[end_idx+1:sep_idx]:\n",
    "                            if inside_op.op_type == \"add_module\": adds[1] += [inside_op]\n",
    "                            if inside_op.op_type == \"mut\": muts[1] += [inside_op]\n",
    "                            if inside_op.op_type == \"rem\": rems[1] += [inside_op]\n",
    "                        if not len(muts[1]):\n",
    "                            for rem_op in rems[1]:\n",
    "                                rem_op.disabler_ops = rem_op.disabler_ops + rems[1]\n",
    "                                rem_op.enabler_ops = rem_op.enabler_ops + adds[1] + [self.operations[-1]]\n",
    "                        \n",
    "                    if value and self.verbose: print(f\"\\t(+{value}) Remove {self.get_op_name(self.model_ops2[j])} (id: {self.model_ops2[j].id}) at indexes {(i,j)}\")\n",
    "                j -=1\n",
    "\n",
    "            elif op == \"mut\":\n",
    "                if self.model_ops1[i].operation.name == \"wrap_end\": self.operations += [MatrixOperation(op_id = len(self.operations),\n",
    "                                                                                          op_type = \"mut_wrap_end\",\n",
    "                                                                                          node1_id = self.model_ops1[i].id,\n",
    "                                                                                          node2_id = self.model_ops2[j].id,\n",
    "                                                                                          i = i,\n",
    "                                                                                          j = j)]\n",
    "                elif self.model_ops1[i].operation.name == \"wrap_sep\": self.operations += [MatrixOperation(op_id = len(self.operations),\n",
    "                                                                                          op_type = \"mut_wrap_sep\",\n",
    "                                                                                          node1_id = self.model_ops1[i].id,\n",
    "                                                                                          node2_id = self.model_ops2[j].id,\n",
    "                                                                                          i = i,\n",
    "                                                                                          j = j)]\n",
    "                else:\n",
    "                    value = self.matrix[i][j].value-self.matrix[i-1][j-1].value\n",
    "                    self.operations += [MatrixOperation(op_id = len(self.operations),\n",
    "                                                  op_type = \"mut\",\n",
    "                                                  node1_id = self.model_ops1[i].id,\n",
    "                                                  node2_id = self.model_ops2[j].id,\n",
    "                                                  i = i,\n",
    "                                                  j = j,\n",
    "                                                  value = value)]\n",
    "                    if value and self.verbose: print(f\"\\t(+{value}) Substitute {self.get_op_name(self.model_ops2[j])} (id: {self.model_ops2[j].id}) by {self.get_op_name(self.model_ops1[i])} (id: {self.model_ops1[i].id}) at indexes {(i,j)}\")\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "            \n",
    "        self.nontrivial_ops = [operation for operation in self.operations if operation.value]\n",
    "    \n",
    "    def generate_offspring(self, selected_ops = None):\n",
    "        if selected_ops == None: selected_ops = self.nontrivial_ops\n",
    "        if self.verbose: print(\">>>Parent model 1\\n\",colored(self.model2, \"red\"), \"\\n>>>Parent model 2\\n\",colored(self.model1, \"green\"),\"\\n\")\n",
    "        \n",
    "        self.performed_ops = []\n",
    "        offspring = self.apply_all_operations(selected_ops, copy.deepcopy(self.model2))\n",
    "        \n",
    "        if self.verbose: print(\">>>Final model\\n\", colored(offspring, \"yellow\"))\n",
    "        return offspring\n",
    "\n",
    "    def apply_all_operations(self, selected_ops, offspring):\n",
    "        for op in selected_ops:\n",
    "            if len(op.enabler_ops): # If we have operations to perform beforehand, we perform them\n",
    "                for branch in op.enabler_ops:\n",
    "                    if type(branch) != list: branch = [branch]\n",
    "                    for op in branch: offspring = self.apply_all_operations([r_op for r_op in branch if r_op in selected_ops], offspring)\n",
    "            offspring = self.apply_op(op, offspring)\n",
    "        return offspring\n",
    "\n",
    "    def apply_op(self, op, offspring):\n",
    "        if op.id not in self.performed_ops:\n",
    "            self.performed_ops += [op.id]\n",
    "            if op.op_type == \"mut\":\n",
    "                for node in self.model_ops1:\n",
    "                    if node.id == op.node1_id:\n",
    "                        node1 = copy.deepcopy(node)\n",
    "                        break\n",
    "\n",
    "                for node in offspring.serialise():\n",
    "                    if (node.id == op.node2_id) or (node.id == op.node1_id):\n",
    "                        node2 = copy.deepcopy(node)\n",
    "                        break\n",
    "                if (not node1.id == op.node1_id) or ((not node.id == op.node2_id) and (not node.id == op.node1_id)): raise Exception(\"Nodes to mutate not found\")\n",
    "                \n",
    "                node1str = str(node1)\n",
    "                if (\"branching\" in node1.operation.name): node1str = node1str.split(\")\")[0]+\")\"+node1str.split(\")\")[1]+\")...}\"\n",
    "                if (\"routing\" in node1.operation.name): node1str = node1str.split(\")\")[0]+\")...]\"\n",
    "                node2str = str(node2)\n",
    "                if (\"branching\" in node2.operation.name): node2str = node2str.split(\")\")[0]+\")\"+node2str.split(\")\")[1]+\")...}\"\n",
    "                if (\"routing\" in node2.operation.name): node2str = node2str.split(\")\")[0]+\")...]\"\n",
    "                if self.verbose: print(\">>>Mutating\",colored(node2str, \"red\"),\"into\", colored(node1str, \"green\"))\n",
    "                \n",
    "                node1.parent = node2.parent\n",
    "                if not node2.is_root(): node2.parent.children[node2.parent.children.index(node2)] = node1\n",
    "                \n",
    "                if (\"branching\" in node1.operation.name) or (\"routing\" in node1.operation.name):\n",
    "                    node1.children[1] = node2.children[1]\n",
    "                    node1.children[1].parent = node1\n",
    "                    if (\"branching(2)\" in node1.operation.name):\n",
    "                        node1.children[2] = node2.children[2]\n",
    "                        node1.children[2].parent = node1\n",
    "                \n",
    "                offspring = node1.get_root()\n",
    "                                    \n",
    "            elif op.op_type == \"rem\":\n",
    "                for node in offspring.serialise():\n",
    "                    if node.id == op.node2_id:\n",
    "                        break\n",
    "                if (not node.id == op.node2_id): print(\">>>Tried to remove module with id\", colored(op.node2_id, \"red\"), \"but it was not found.\")\n",
    "                else:\n",
    "                    if \"branching(2)\" in node.operation.name:\n",
    "                        b1 = node.children[1]\n",
    "                        b2 = node.children[2]\n",
    "                        if self.verbose: print(\">>>Serializing branches\",colored(str(b1), \"red\"),\"and\",colored(str(b2), \"red\"))\n",
    "                        \n",
    "                        sequential_node = DerivationTreeNode(0,\n",
    "                                                             level=node.level,\n",
    "                                                             parent=node.parent,\n",
    "                                                             input_params=node.input_params,\n",
    "                                                             depth=node.depth,\n",
    "                                                             limiter=node.limiter,\n",
    "                                                             operation = Operation(name=\"sequential\",\n",
    "                                                                                   build=einspace.build_sequential_module,\n",
    "                                                                                   infer=einspace.infer_sequential_module,\n",
    "                                                                                   valid=einspace.valid_sequential_module,\n",
    "                                                                                   inherit = [einspace.inherit_first_child,einspace.inherit_other_child],\n",
    "                                                                                   give_back = [einspace.give_back_default,einspace.give_back_default],\n",
    "                                                                                   type=\"nonterminal\",\n",
    "                                                                                   child_levels=[\"module\",\"module\"])\n",
    "                                                        )\n",
    "                        self.update_id(sequential_node)\n",
    "                        sequential_node.children=[b1, b2]\n",
    "                        b1.parent = sequential_node\n",
    "                        b2.parent = sequential_node\n",
    "                        if node.parent: node.parent.children[node.parent.children.index(node)] = sequential_node\n",
    "                        offspring = sequential_node.get_root()\n",
    "                        \n",
    "                    else:\n",
    "                        nodestr = str(node)\n",
    "                        if (\"branching\" in node.operation.name): nodestr = nodestr.split(\")\")[0]+\")\"+nodestr.split(\")\")[1]+\")...}\"\n",
    "                        if (\"routing\" in node.operation.name): nodestr = nodestr.split(\")\")[0]+\")...]\"\n",
    "                        if self.verbose: print(\">>>Removing\", colored(nodestr, \"red\"))\n",
    "                            \n",
    "                        parent_node = node.parent\n",
    "                        \n",
    "                        if (\"branching\" in node.operation.name) or (\"routing\" in node.operation.name):\n",
    "                            if parent_node: parent_node.children[parent_node.children.index(node)] = node.children[1]\n",
    "                            node.children[1].parent = node.parent\n",
    "                            offspring = node.children[1].get_root()\n",
    "                        else:\n",
    "                            sibling_node = parent_node.children[parent_node.children.index(node)-1]\n",
    "                            if not parent_node.is_root():\n",
    "                                sibling_node.parent = parent_node.parent\n",
    "                                parent_node.parent.children[parent_node.parent.children.index(parent_node)] = sibling_node\n",
    "                            else:\n",
    "                                sibling_node.parent = None\n",
    "                                \n",
    "                            offspring = sibling_node.get_root()\n",
    "                            \n",
    "            elif op.op_type == \"add_module\":\n",
    "                for node in self.model_ops1:\n",
    "                    if node.id == op.node1_id:\n",
    "                        node1 = copy.deepcopy(node)\n",
    "                        break\n",
    "                if (not node1.id == op.node1_id): raise Exception(\"Node\",op.node1_id,\"not found from model 1 when attempting module addition\")\n",
    "                if op.node2_id == -1:\n",
    "                    node2 = offspring\n",
    "                    add_at_the_end = False\n",
    "                else:\n",
    "                    last_node_pos = [0,0] # We look for the id of the node we want to add the module before\n",
    "                    jjj = 1 # which will come from the second model if we parallelized the first branch\n",
    "                    if op.j+jjj < len(self.model_ops2):\n",
    "                        while self.model_ops2[op.j+jjj].id not in [n.id for n in offspring.serialise()]:\n",
    "                            jjj += 1\n",
    "                            if op.j+jjj == len(self.model_ops2): break\n",
    "                    if op.j+jjj < len(self.model_ops2):\n",
    "                        op_name2 = self.model_ops2[op.j+jjj].operation.name\n",
    "                        while offspring.serialise()[last_node_pos[0]].id != self.model_ops2[op.j+jjj].id:\n",
    "                            last_node_pos[0] = last_node_pos[0] + 1\n",
    "                            if last_node_pos[0] == len(offspring.serialise()): break\n",
    "                    else:\n",
    "                        op_name2 = \"\"\n",
    "                        last_node_pos[0] = len(offspring.serialise())\n",
    "                    iii = 0 # or from the first model if we added the first branch\n",
    "                    if op.i+iii < len(self.model_ops1):\n",
    "                        while self.model_ops1[op.i+iii].id not in [n.id for n in offspring.serialise()]:\n",
    "                            iii += 1\n",
    "                            if op.i+iii == len(self.model_ops1): break\n",
    "                    if op.i+iii < len(self.model_ops1):\n",
    "                        op_name1 = self.model_ops1[op.i+iii].operation.name\n",
    "                        while offspring.serialise()[last_node_pos[1]].id != self.model_ops1[op.i+iii].id:\n",
    "                            last_node_pos[1] = last_node_pos[1] + 1\n",
    "                            if last_node_pos[1] == len(offspring.serialise()): break\n",
    "                    else:\n",
    "                        op_name1 = \"\"\n",
    "                        last_node_pos[1] = len(offspring.serialise())\n",
    "\n",
    "                    if min(last_node_pos) == len(offspring.serialise()):\n",
    "                        node2 = node1\n",
    "                        node1 = offspring\n",
    "                        add_at_the_end = True\n",
    "                    \n",
    "                    else:\n",
    "                        pos_scores = last_node_pos.copy()\n",
    "                        if (pos_scores[0] < len(offspring.serialise())) and (\"wrap_\" in op_name2): pos_scores[0] = pos_scores[0] + num_of_children(offspring.serialise()[last_node_pos[0]])\n",
    "                        if (pos_scores[1] < len(offspring.serialise())) and (\"wrap_\" in op_name1): pos_scores[1] = pos_scores[1] + num_of_children(offspring.serialise()[last_node_pos[1]])\n",
    "                        chosen_pos = pos_scores.index(min(pos_scores))\n",
    "                        if [\"wrap_\" in op_name2, \"wrap_\" in op_name1][chosen_pos]:\n",
    "                            node2 = node1\n",
    "                            node1 = offspring.serialise()[last_node_pos[chosen_pos]].children[-2]\n",
    "                            add_at_the_end = True\n",
    "                        else:\n",
    "                            node2 = offspring.serialise()[last_node_pos[chosen_pos]]\n",
    "                            add_at_the_end = False\n",
    "                \n",
    "                sequential_node = DerivationTreeNode(0,\n",
    "                                                     level=node.level,\n",
    "                                                     parent=None,\n",
    "                                                     input_params=node.input_params,\n",
    "                                                     depth=node2.depth,\n",
    "                                                     limiter=node.limiter,\n",
    "                                                     operation = Operation(name=\"sequential\",\n",
    "                                                                           build=einspace.build_sequential_module,\n",
    "                                                                           infer=einspace.infer_sequential_module,\n",
    "                                                                           valid=einspace.valid_sequential_module,\n",
    "                                                                           inherit = [einspace.inherit_first_child,einspace.inherit_other_child],\n",
    "                                                                           give_back = [einspace.give_back_default,einspace.give_back_default],\n",
    "                                                                           type=\"nonterminal\",\n",
    "                                                                           child_levels=[\"module\",\"module\"])\n",
    "                                                )\n",
    "\n",
    "                self.update_id(sequential_node)\n",
    "                \n",
    "                if add_at_the_end:\n",
    "                    sequential_node.parent = node1.parent\n",
    "                    if not node1.is_root():\n",
    "                        node1.parent.children[node1.parent.children.index(node1)] = sequential_node\n",
    "                else:\n",
    "                    sequential_node.parent = node2.parent\n",
    "                    if not node2.is_root():\n",
    "                        node2.parent.children[node2.parent.children.index(node2)] = sequential_node\n",
    "                    \n",
    "                sequential_node.children=[node1, node2]\n",
    "                node1.parent = sequential_node\n",
    "                node2.parent = sequential_node\n",
    "                \n",
    "                offspring = sequential_node.get_root()\n",
    "                \n",
    "                if self.verbose:\n",
    "                    if add_at_the_end: print(\">>>Adding\", colored(str(node2), \"green\"), \"after\", colored(str(node1), \"red\"))\n",
    "                    else: print(\">>>Adding\", colored(str(node1), \"green\"), \"before\", colored(str(node2), \"red\"))\n",
    "                \n",
    "            elif op.op_type == \"add_wrap\":\n",
    "                for node in self.model_ops1:\n",
    "                    if node.id == op.node1_id:\n",
    "                        node1 = copy.deepcopy(node)\n",
    "                        break\n",
    "                \n",
    "                split_pos = [0,0] # We look for the id of the node we want to start the wrap at\n",
    "                jjj = 1 # which will come from the second model if we parallelized the first branch\n",
    "                if op.j+jjj < len(self.model_ops2):\n",
    "                    while (\"wrap_\" in self.model_ops2[op.j+jjj].operation.name) or (self.model_ops2[op.j+jjj].id not in [n.id for n in offspring.serialise()]):\n",
    "                        jjj += 1\n",
    "                        if op.j+jjj == len(self.model_ops2): break\n",
    "                if op.j+jjj < len(self.model_ops2):\n",
    "                    while offspring.serialise()[split_pos[0]].id != self.model_ops2[op.j+jjj].id:\n",
    "                        split_pos[0] = split_pos[0] + 1\n",
    "                        if split_pos[0] == len(offspring.serialise()): break\n",
    "                else: split_pos[0] = len(offspring.serialise())\n",
    "                iii = 0 # or from the first model if we added the first branch\n",
    "                if op.i+iii < len(self.model_ops1):\n",
    "                    while (\"wrap_\" in self.model_ops1[op.i+iii].operation.name) or (self.model_ops1[op.i+iii].id not in [n.id for n in offspring.serialise()]):\n",
    "                        iii += 1\n",
    "                        if op.i+iii == len(self.model_ops1): break\n",
    "                if op.i+iii < len(self.model_ops1):\n",
    "                    while offspring.serialise()[split_pos[1]].id != self.model_ops1[op.i+iii].id:\n",
    "                        split_pos[1] = split_pos[1] + 1\n",
    "                        if split_pos[1] == len(offspring.serialise()): break\n",
    "                else: split_pos[1] = len(offspring.serialise())\n",
    "                \n",
    "                node = offspring.serialise()[min(split_pos)]\n",
    "                # If the previous layer we found is the start of a branch/rout coming from the first model, we are interested on its children\n",
    "                if (len(node.children) == 3) and (min(split_pos) == split_pos[0]): node = node.children[1]\n",
    "                starting_node = node\n",
    "                split_pos = [0,0] # We look for the id of the next node after we end the wrap\n",
    "                jjj = 0 # which will come from the second model if we didn't have to add the inside modules\n",
    "                if op.jj+jjj < len(self.model_ops2):\n",
    "                    op_name2 = self.model_ops2[op.jj+jjj].operation.name\n",
    "                    while self.model_ops2[op.jj+jjj].id not in [n.id for n in offspring.serialise()]:\n",
    "                        jjj += 1\n",
    "                        if op.jj+jjj == len(self.model_ops2): break\n",
    "                if op.jj+jjj < len(self.model_ops2):\n",
    "                    while offspring.serialise()[split_pos[0]].id != self.model_ops2[op.jj+jjj].id:\n",
    "                        split_pos[0] = split_pos[0] + 1\n",
    "                        if split_pos[0] == len(offspring.serialise()): break\n",
    "                else:\n",
    "                    op_name2 = \"\"\n",
    "                    split_pos[0] = len(offspring.serialise())\n",
    "                iii = 0 # or from the first model if we did\n",
    "                if op.ii+iii < len(self.model_ops1):\n",
    "                    while self.model_ops1[op.ii+iii].id not in [n.id for n in offspring.serialise()]:\n",
    "                        iii += 1\n",
    "                        if op.ii+iii == len(self.model_ops1): break\n",
    "                if op.ii+iii < len(self.model_ops1):\n",
    "                    op_name1 = self.model_ops1[op.ii+iii].operation.name\n",
    "                    while offspring.serialise()[split_pos[1]].id != self.model_ops1[op.ii+iii].id:\n",
    "                        split_pos[1] = split_pos[1] + 1\n",
    "                        if split_pos[1] == len(offspring.serialise()): break\n",
    "                else:\n",
    "                    op_name1 = \"\"\n",
    "                    split_pos[1] = len(offspring.serialise())\n",
    "                \n",
    "                if min(split_pos) == len(offspring.serialise()): # If we need to wrap up until the end of the model\n",
    "                    split_pos = len(offspring.serialise())\n",
    "                    found_parent_sequential = False\n",
    "                    while not found_parent_sequential: # We need to find the sequential node that holds the modules up to the end of the model\n",
    "                        if not node.is_root():\n",
    "                            if (node.parent.operation.name == \"sequential\") and (offspring.serialise()[-1] not in node.serialise()): node = node.parent \n",
    "                            else: found_parent_sequential = True\n",
    "                        else: found_parent_sequential = True\n",
    "                else: # If we need to wrap up until a certain module\n",
    "                    if split_pos[0] == len(offspring.serialise()): split_pos[0] = -1\n",
    "                    if split_pos[1] == len(offspring.serialise()): split_pos[1] = -1\n",
    "                    chosen_pos = split_pos.index(max(split_pos))\n",
    "                    split_pos = split_pos[chosen_pos]\n",
    "                    found_parent_sequential = False\n",
    "                    while not found_parent_sequential: # We need to find the sequential node that holds up to the module we woould like to wrap\n",
    "                        if not node.is_root():\n",
    "                            if (node.parent.operation.name == \"sequential\") and (offspring.serialise()[split_pos] not in node.serialise()): node = node.parent \n",
    "                            else: found_parent_sequential = True\n",
    "                        else: found_parent_sequential = True\n",
    "                \n",
    "                if (split_pos == len(offspring.serialise())) or [\"wrap_\" in op_name2, \"wrap_\" in op_name1][chosen_pos]: end_at_id = -1 # If we are wrapping until the end of the model nor a wrap_end,\n",
    "                else: end_at_id = offspring.serialise()[split_pos].id # we save the id of the last node to split the sequentials at further on\n",
    "                \n",
    "                if node.operation.name == \"sequential\":\n",
    "                    try:\n",
    "                        node = self.split_sequentials(node, starting_node.id).children[1] # We resequentialize the modules to be able to fit the wrap where we want it to be\n",
    "                    except: # If we couldn't split it, it means that the original sequential already started with the first module we are insterested in\n",
    "                        node = node\n",
    "                else: node = node\n",
    "                if node.operation.name == \"sequential\": # If  we are wrapping a sequential module\n",
    "                    if end_at_id != -1: # and we have a valid end id,\n",
    "                        try: node2 = self.split_sequentials(node, end_at_id).children[0] # we resequentialize the modules to be able to fit the wrap where we want it to be\n",
    "                        except: node2 = node\n",
    "                    else: node2 = node\n",
    "                else: node2 = node\n",
    "\n",
    "                if self.verbose: print(\">>>Adding wrapper\", colored(node1.operation.name, \"green\"), \"around\", colored(str(node2), \"red\"))\n",
    "                node1.parent = node2.parent\n",
    "                if not node2.is_root(): node2.parent.children[node2.parent.children.index(node2)] = node1\n",
    "                node1.children[1] = node2\n",
    "                node2.parent = node1\n",
    "                offspring = node1.get_root()\n",
    "\n",
    "            elif op.op_type == \"add_branch2\":\n",
    "                for node in self.model_ops1:\n",
    "                    if node.id == op.node1_id:\n",
    "                        node1 = copy.deepcopy(node)\n",
    "                        break\n",
    "\n",
    "                split_pos = [0, 0] # We look for the id of the node we want to start the parallelization at\n",
    "                jjj = 1 # which will come from the second model if we already had the first node from the first branch\n",
    "                if op.j+jjj < len(self.model_ops2):\n",
    "                    while (\"wrap_\" in self.model_ops2[op.j+jjj].operation.name) or (self.model_ops2[op.j+jjj].id not in [n.id for n in offspring.serialise()]):\n",
    "                        jjj += 1\n",
    "                        if op.j+jjj == len(self.model_ops2): break\n",
    "                if op.j+jjj < len(self.model_ops2):\n",
    "                    while offspring.serialise()[split_pos[0]].id != self.model_ops2[op.j+jjj].id:\n",
    "                        split_pos[0] = split_pos[0] + 1\n",
    "                        if split_pos[0] == len(offspring.serialise()): break\n",
    "                else: split_pos[0] = len(offspring.serialise())\n",
    "                \n",
    "                iii = 0 # or from the first model if we had to add the first node from the first branch\n",
    "                if op.i+iii < len(self.model_ops1):\n",
    "                    while (\"wrap_\" in self.model_ops1[op.i+iii].operation.name) or (self.model_ops1[op.i+iii].id not in [n.id for n in offspring.serialise()]):\n",
    "                        iii += 1\n",
    "                        if op.i+iii == len(self.model_ops1): break\n",
    "                if op.i+iii < len(self.model_ops1):\n",
    "                    while offspring.serialise()[split_pos[1]].id != self.model_ops1[op.i+iii].id:\n",
    "                        split_pos[1] += 1\n",
    "                        if split_pos[1] == len(offspring.serialise()): break\n",
    "                else: split_pos[1] = len(offspring.serialise())\n",
    "\n",
    "                node = offspring.serialise()[min(split_pos)]\n",
    "                starting_node = node\n",
    "\n",
    "                split_pos = [0,0] # We look for the id of the next node after we end the second branch\n",
    "                jjj = 1 # which will come from the second model if we already had it in the offspring\n",
    "                if op.jj[1]+jjj < len(self.model_ops2):\n",
    "                    op_name2 = self.model_ops2[op.jj[1]+jjj].operation.name\n",
    "                    while self.model_ops2[op.jj[1]+jjj].id not in [n.id for n in offspring.serialise()]:\n",
    "                        jjj += 1\n",
    "                        if op.jj[1]+jjj == len(self.model_ops2): break\n",
    "                if op.jj[1]+jjj < len(self.model_ops2):\n",
    "                    while offspring.serialise()[split_pos[0]].id != self.model_ops2[op.jj[1]+jjj].id:\n",
    "                        split_pos[0] = split_pos[0] + 1\n",
    "                        if split_pos[0] == len(offspring.serialise()): break\n",
    "                else:\n",
    "                    op_name2 = \"\"\n",
    "                    split_pos[0] = len(offspring.serialise())\n",
    "                    \n",
    "                iii = 0 # or from the first model if we didn't\n",
    "                if op.ii[1]+iii < len(self.model_ops1):\n",
    "                    while self.model_ops1[op.ii[1]+iii].id not in [n.id for n in offspring.serialise()]:\n",
    "                        iii += 1\n",
    "                        if op.ii[1]+iii == len(self.model_ops1): break\n",
    "                if op.ii[1]+iii < len(self.model_ops1):\n",
    "                    op_name1 = self.model_ops1[op.ii[1]+iii].operation.name\n",
    "                    while offspring.serialise()[split_pos[1]].id != self.model_ops1[op.ii[1]+iii].id:\n",
    "                        split_pos[1] = split_pos[1] + 1\n",
    "                        if split_pos[1] == len(offspring.serialise()): break\n",
    "                else:\n",
    "                    op_name1 = \"\"\n",
    "                    split_pos[1] = len(offspring.serialise())\n",
    "\n",
    "                if min(split_pos) == len(offspring.serialise()): # If we need to wrap up until the end of the model\n",
    "                    split_pos = len(offspring.serialise())\n",
    "                    found_parent_sequential = False\n",
    "                    while not found_parent_sequential: # We need to find the sequential node that holds the modules up to the end of the model\n",
    "                        if not node.is_root():\n",
    "                            if (node.parent.operation.name == \"sequential\") and (offspring.serialise()[-1] not in node.serialise()): node = node.parent \n",
    "                            else: found_parent_sequential = True\n",
    "                        else: found_parent_sequential = True\n",
    "                else: # If we need to wrap up until a certain module\n",
    "                    if split_pos[0] == len(offspring.serialise()): split_pos[0] = -1\n",
    "                    if split_pos[1] == len(offspring.serialise()): split_pos[1] = -1\n",
    "                    chosen_pos = split_pos.index(max(split_pos))\n",
    "                    split_pos = split_pos[chosen_pos]\n",
    "                    found_parent_sequential = False\n",
    "                    while not found_parent_sequential: # We need to find the sequential node that holds up to the module we woould like to wrap\n",
    "                        if not node.is_root():\n",
    "                            if (node.parent.operation.name == \"sequential\") and (offspring.serialise()[split_pos] not in node.serialise()): node = node.parent \n",
    "                            else: found_parent_sequential = True\n",
    "                        else: found_parent_sequential = True\n",
    "\n",
    "                if (split_pos == len(offspring.serialise())) or [\"wrap_\" in op_name2, \"wrap_\" in op_name1][chosen_pos]: end_at_id = -1 # If we are wrapping until the end of the model nor a wrap_end,\n",
    "                else: end_at_id = offspring.serialise()[split_pos].id # we save the id of the last node to split the sequentials at further on\n",
    "                    \n",
    "                if node.operation.name == \"sequential\":\n",
    "                    try:\n",
    "                        node = self.split_sequentials(node, starting_node.id).children[1] # We resequentialize the modules to be able to fit the branch(2) where we want it to be\n",
    "                    except: # If we couldn't split it, it means that the original sequential already started with the first module we are insterested in\n",
    "                        node = node\n",
    "                else: node = node\n",
    "\n",
    "                if node.operation.name == \"sequential\": # If  we are wrapping a sequential module\n",
    "                    if end_at_id != -1: # and we have a valid end id,\n",
    "                        try: node2 = self.split_sequentials(node, end_at_id).children[0] # we resequentialize the modules to be able to fit the wrap where we want it to be\n",
    "                        except: node2 = node\n",
    "                    else: node2 = node\n",
    "                else: node2 = node\n",
    "\n",
    "                split_pos = [0, 0] # We look for the id of the node we want to start the second branch at\n",
    "                jjj = 1 # which will come from the second model if we already had the second branch\n",
    "                if op.jj[0]+jjj < len(self.model_ops2):\n",
    "                    while (\"wrap_\" in self.model_ops2[op.jj[0]+jjj].operation.name) or (self.model_ops2[op.jj[0]+jjj].id not in [n.id for n in node2.serialise()]):\n",
    "                        jjj += 1\n",
    "                        if op.jj[0]+jjj == len(self.model_ops2): break\n",
    "                if op.jj[0]+jjj < len(self.model_ops2):\n",
    "                    while node2.serialise()[split_pos[0]].id != self.model_ops2[op.jj[0]+jjj].id:\n",
    "                        split_pos[0] = split_pos[0] + 1\n",
    "                        if split_pos[0] == len(node2.serialise()): break\n",
    "                else: split_pos[0] = len(node2.serialise())\n",
    "                \n",
    "                iii = 0 # or from the first model if we added the second branch\n",
    "                if op.ii[0]+iii < len(self.model_ops1):\n",
    "                    while (\"wrap_\" in self.model_ops1[op.ii[0]+iii].operation.name) or (self.model_ops1[op.ii[0]+iii].id not in [n.id for n in node2.serialise()]):\n",
    "                        iii += 1\n",
    "                        if op.ii[0]+iii == len(self.model_ops1): break\n",
    "                if op.ii[0]+iii < len(self.model_ops1):\n",
    "                    while node2.serialise()[split_pos[1]].id != self.model_ops1[op.ii[0]+iii].id:\n",
    "                        split_pos[1] += 1\n",
    "                        if split_pos[1] == len(node2.serialise()): break\n",
    "                else: split_pos[1] = len(node2.serialise())\n",
    "\n",
    "                if (node2.operation.name == \"sequential\") and (min(split_pos) < len(node2.serialise())):\n",
    "                    node2 = self.split_sequentials(node2, node2.serialise()[min(split_pos)].id) # We resequentialize the modules to be able to split the branches right where we want to\n",
    "                else: node2 = node2\n",
    "\n",
    "                if self.verbose: print(\">>>Parallelizing modules\", colored(str(node2.children[0]), \"red\"), \"and\", colored(str(node2.children[1]), \"red\"), \"using\", colored(node1.operation.name, \"green\"))\n",
    "\n",
    "                parent_node = node2.parent\n",
    "                if not node2.is_root(): parent_node.children[parent_node.children.index(node2)] = node1\n",
    "                node1.parent = parent_node\n",
    "                node1.children[1] = node2.children[0]\n",
    "                node1.children[2] = node2.children[1]\n",
    "                node2.children[0].parent = node1\n",
    "                node2.children[1].parent = node1\n",
    "                offspring = node1.get_root()\n",
    "            \n",
    "            if self.verbose and (\"wrap_end\" not in op.op_type) and (\"wrap_sep\" not in op.op_type): print(\"\",colored(offspring, \"light_grey\"), \"\\n\")\n",
    "        return offspring\n",
    "\n",
    "\n",
    "def num_of_children(node, n = 0):\n",
    "    for child in node.children:\n",
    "        n = n + 1 + num_of_children(child)\n",
    "    return n\n",
    "\n",
    "\n",
    "def select_operations(operations, skewness = 0):\n",
    "    combinations = {}\n",
    "    for i in range(2**len(operations)):\n",
    "        combo_str = bin(i)[2:].zfill(len(operations))\n",
    "        ops = [op for idx, op in enumerate(operations) if combo_str[idx] == \"1\"]\n",
    "        value = sum([op.value for op in ops])\n",
    "        for op in ops:\n",
    "            # We take all enabler operations and separate them by branch (we add non-branch operations as if they were a branch)\n",
    "            enablers = [op_en for op_en in op.enabler_ops if type(op_en) == list] + [[op_en for op_en in op.enabler_ops if type(op_en) != list]]\n",
    "            # We do the same for the disabler operations\n",
    "            disablers = [op_dis for op_dis in op.disabler_ops if type(op_dis) == list] + [[op_dis for op_dis in op.disabler_ops if type(op_dis) != list]]\n",
    "            for b in range(len(enablers)):\n",
    "                if len(disablers[b]) and all([disabler in ops for disabler in disablers[b]]) and (not any([enabler in ops for enabler in enablers[b]])): value = np.nan\n",
    "        if not np.isnan(value): combinations[combo_str] = value\n",
    "\n",
    "    sknorm = skewnorm(skewness)\n",
    "    sample_resolution = 4\n",
    "    sample_at = np.linspace(sknorm.ppf(0.01), sknorm.ppf(0.99), int(combinations[max(combinations)]*sample_resolution))\n",
    "    samples = sknorm.pdf(sample_at)\n",
    "    probs = [samples[int(combinations[c]*sample_resolution)-1] for c in combinations]\n",
    "    probs /= np.sum(probs)\n",
    "    \n",
    "    selected = np.random.choice([c for c in combinations], p = probs)\n",
    "    \n",
    "    return [operations[i] for i, v in enumerate(selected) if v == \"1\"]\n",
    "\n",
    "\n",
    "def constrained_smith_waterman_crossover(parent1, parent2):\n",
    "    # build alignment matrix\n",
    "    matrix = AlignmentMatrix(parent1, parent2, priorities=(\"mut\", \"add\", \"rem\"), verbose=False)\n",
    "    operations = matrix.nontrivial_ops\n",
    "    if len(operations) == 0:\n",
    "        return parent1, []\n",
    "    else:\n",
    "        # sample random operations along the shortest path\n",
    "        selected_ops = select_operations(operations)\n",
    "        # perform the operations to generate the offspring\n",
    "        child = matrix.generate_offspring(selected_ops, skewness = 0)\n",
    "        return child, corrected_ops\n",
    "\n",
    "def compile_fn(node, args):\n",
    "    backbone = node.build(node, set_memory_checkpoint=True)\n",
    "    return Network(\n",
    "        backbone,\n",
    "        node.output_params[\"shape\"],\n",
    "        args.num_classes,\n",
    "        vars(args)\n",
    "    ).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"models.pkl\", \"rb\") as f:\n",
    "    models = pickle.load(f)\n",
    "m1 = models[\"m1\"]\n",
    "m2 = models[\"m2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = AlignmentMatrix(m2, m1, priorities = (\"mut\", \"add\", \"rem\"), verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "offspring = matrix.generate_offspring(matrix.nontrivial_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_derivation_tree(search.evolver.re_id(offspring))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = AlignmentMatrix(m2, m1, priorities = (\"mut\", \"add\", \"rem\"), verbose = False)\n",
    "for i in range(len(matrix.nontrivial_ops)):\n",
    "    offspring = matrix.generate_offspring(matrix.nontrivial_ops[:i])\n",
    "    visualise_derivation_tree(search.evolver.re_id(offspring))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
